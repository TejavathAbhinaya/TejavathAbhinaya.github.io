---
title: 'Journey into the World of Artificial Intelligence in Medical Imaging'
date: 06-09-2023
permalink: /posts/2012/08/blog-post-1/
tags:
  - Artificial Intelligence (AI)
  - Medical Imaging
  - Vision Transformers
---

The world of Artificial Intelligence (AI) is vast, but my academic and research journey at the National Institute of Technology (NIT) has helped me channel my focus towards some of its most cutting-edge facets. From the foundational principles of Electrical and Electronics Engineering during my Bachelor's at NIT Calicut to the deep intricacies of AI in my M.Tech at NIT Bhopal, my path has been one of continuous learning and exploration.

Why Deep Learning?
Deep Learning, a subset of AI, has always intrigued me due to its capacity to model and process non-linear relationships. But what captured my interest further was its application in medical image processing. I was particularly interested in the use of vision transformers for medical imaging.

The Allure of Vision Transformers:
In the world of artificial intelligence, innovations often cross-pollinate across domains, leading to transformative advancements. Such was the case with the birth and evolution of Vision Transformers (ViTs). The tale began in 2017 when Vaswani and his team introduced transformers in their seminal paper, "Attention is All You Need". This architecture, with its self-attention mechanism, redefined what was possible in Natural Language Processing (NLP). But the boundaries of language were not the limits for transformers. Vision, another profound domain of AI, beckoned. Pioneering researchers started to dissect images into fixed-sized patches, treating them analogously to the tokens in NLP. Each image patch became a "token", processed with the transformative power of the transformer architecture. This was a paradigm shift from the traditional Convolutional Neural Networks (CNNs) that worked hierarchically, moving from low-level to high-level features. ViTs, on the contrary, processed all patches, or "tokens", simultaneously, capturing a dance of global dependencies and a richer feature interplay. But challenges arose, most notably the data-hungry nature of ViTs. Initially, ViTs showcased their prowess in environments abundant with data. However, the real world isn't always as generous. The AI community responded, experimenting with data augmentation, hybrid models, and even blending the best of CNNs and ViTs. Techniques like transfer learning came to the fore, where knowledge from a pre-trained behemoth ViT was distilled into smaller, more manageable models. With time, several ViT variants blossomed, offering tailored solutions to diverse challenges. The promise of ViTs even echoed in niche domains like medical imaging. Their ability to discern nuanced patterns made them a valuable asset, a sentiment I experienced firsthand in my research on the early diagnosis of endometrial tumors. Today, as we stand at the crossroads of innovation and application, the journey of Vision Transformers from the realms of language to the intricacies of vision stands testament to the ever-evolving, adaptable nature of AI.

Projects and Hands-on Experience:
Theoretical knowledge, while foundational, gains true value when applied. My hands-on projects like implementing the YOLO V7, Deep SORT, and attention-augmented methodologies have been enlightening. They've bridged the gap between theoretical constructs and real-world applications. I have worked on a number of projects that use vision transformers and advanced neural architectures. One of my projects involved using a ViT to classify histopathology images of endometrial cancer. I was able to achieve a state-of-the-art accuracy on this task. 

